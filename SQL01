-- show running queries (pre 9.2)
SELECT procpid, age(clock_timestamp(), query_start), usename, current_query 
FROM pg_stat_activity 
WHERE current_query != '<IDLE>' AND current_query NOT ILIKE '%pg_stat_activity%' 
ORDER BY query_start desc;

-- show running queries (9.2)
SELECT pid, age(clock_timestamp(), query_start), usename, query 
FROM pg_stat_activity 
WHERE query != '<IDLE>' AND query NOT ILIKE '%pg_stat_activity%' 
ORDER BY query_start desc;

-- kill running query
SELECT pg_cancel_backend(procpid);

-- kill idle query
SELECT pg_terminate_backend(procpid);

-- vacuum command
VACUUM (VERBOSE, ANALYZE);

-- all database users
select * from pg_stat_activity where current_query not like '<%';

-- all databases and their sizes
select * from pg_user;

-- all tables and their size, with/without indexes
select datname, pg_size_pretty(pg_database_size(datname))
from pg_database
order by pg_database_size(datname) desc;

-- cache hit rates (should not be less than 0.99)
SELECT sum(heap_blks_read) as heap_read, sum(heap_blks_hit)  as heap_hit, (sum(heap_blks_hit) - sum(heap_blks_read)) / sum(heap_blks_hit) as ratio
FROM pg_statio_user_tables;

-- table index usage rates (should not be less than 0.99)
SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table
FROM pg_stat_user_tables 
ORDER BY n_live_tup DESC;

-- how many indexes are in cache
SELECT sum(idx_blks_read) as idx_read, sum(idx_blks_hit)  as idx_hit, (sum(idx_blks_hit) - sum(idx_blks_read)) / sum(idx_blks_hit) as ratio
FROM pg_statio_user_indexes;

-- Dump database on remote host to file
$ pg_dump -U username -h hostname databasename > dump.sql

-- Import dump into existing database
$ psql -d newdb -f dump.sql

--Index/columns
select
    t.relname as table_name,
    i.relname as index_name,
    string_agg(a.attname, ',') as column_name
from
    pg_class t,
    pg_class i,
    pg_index ix,
    pg_attribute a
where
    t.oid = ix.indrelid
    and i.oid = ix.indexrelid
    and a.attrelid = t.oid
    and a.attnum = ANY(ix.indkey)
    and t.relkind = 'r'
    and t.relname not like 'pg_%'
group by  
    t.relname,
    i.relname
order by
    t.relname,
    i.relname;

    To avoid divided
by zero error
-- Anomalies
select datname, (xact_commit*100)/nullif(xact_commit+xact_rollback,0) as c_commit_ratio, (xact_rollback*100)/nullif(xact_commit+xact_rollback, 0) as c_rollback_ratio, deadlocks, conflicts, temp_files, pg_size_pretty(temp_bytes)
from pg_stat_database;


--Tables: table/index/TOAST size, number of rows

with data as (
  select
    c.oid,
    (select spcname from pg_tablespace where oid = reltablespace) as tblspace,
    nspname as schema_name,
    relname as table_name,
    c.reltuples as row_estimate,
    pg_total_relation_size(c.oid) as total_bytes,
    pg_indexes_size(c.oid) as index_bytes,
    pg_total_relation_size(reltoastrelid) as toast_bytes,
    pg_total_relation_size(c.oid) - pg_indexes_size(c.oid) - coalesce(pg_total_relation_size(reltoastrelid), 0) as table_bytes
  from pg_class c
  left join pg_namespace n on n.oid = c.relnamespace
  where relkind = 'r' and nspname <> 'pg_catalog'
), data2 as (
  select
    null::oid as oid,
    null as tblspace,
    null as schema_name,
    '*** TOTAL ***' as table_name,
    sum(row_estimate) as row_estimate,
    sum(total_bytes) as total_bytes,
    sum(index_bytes) as index_bytes,
    sum(toast_bytes) as toast_bytes,
    sum(table_bytes) as table_bytes
  from data
  union all
  select
    null::oid as oid,
    null,
    null as schema_name,
    '    tablespace: [' || coalesce(tblspace, 'pg_default') || ']' as table_name,
    sum(row_estimate) as row_estimate,
    sum(total_bytes) as total_bytes,
    sum(index_bytes) as index_bytes,
    sum(toast_bytes) as toast_bytes,
    sum(table_bytes) as table_bytes
  from data
  where (select count(distinct coalesce(tblspace, 'pg_default')) from data) > 1 -- don't show this part if there are no custom tablespaces
  group by tblspace
  union all
  select null::oid, null, null, null, null, null, null, null, null
  union all
  select * from data
)
select
  coalesce(nullif(schema_name, 'public') || '.', '') || table_name || coalesce(' [' || tblspace || ']', '') as "Table",
  '~' || case
    when row_estimate > 10^12 then round(row_estimate::numeric / 10^12::numeric, 0)::text || 'T'
    when row_estimate > 10^9 then round(row_estimate::numeric / 10^9::numeric, 0)::text || 'B'
    when row_estimate > 10^6 then round(row_estimate::numeric / 10^6::numeric, 0)::text || 'M'
    when row_estimate > 10^3 then round(row_estimate::numeric / 10^3::numeric, 0)::text || 'k'
    else row_estimate::text
  end as "Rows",
  pg_size_pretty(total_bytes) || ' (' || round(
    100 * total_bytes::numeric / nullif(sum(total_bytes) over (partition by (schema_name is null), left(table_name, 3) = '***'), 0),
    2
  )::text || '%)' as "Total Size",
  pg_size_pretty(table_bytes) || ' (' || round(
    100 * table_bytes::numeric / nullif(sum(table_bytes) over (partition by (schema_name is null), left(table_name, 3) = '***'), 0),
    2
  )::text || '%)' as "Table Size",
  pg_size_pretty(index_bytes) || ' (' || round(
    100 * index_bytes::numeric / nullif(sum(index_bytes) over (partition by (schema_name is null), left(table_name, 3) = '***'), 0),
    2
  )::text || '%)' as "Index(es) Size",
  pg_size_pretty(toast_bytes) || ' (' || round(
    100 * toast_bytes::numeric / nullif(sum(toast_bytes) over (partition by (schema_name is null), left(table_name, 3) = '***'), 0),
    2
  )::text || '%)' as "TOAST Size"
from data2
where schema_name is distinct from 'information_schema'
order by oid is null desc, total_bytes desc nulls last;


--Load profile

with
    data
    as
    (
        select
            s.relname as table_name,
            s.schemaname as schema_name,
            (select spcname
            from pg_tablespace
            where oid = reltablespace) as tblspace,
            c.reltuples as row_estimate,
            *,
            case when n_tup_upd = 0 then null else n_tup_hot_upd::numeric / n_tup_upd end as upd_hot_ratio,
            -- wrong! seq_tup_read + coalesce(idx_tup_fetch, 0) - n_tup_del - n_tup_upd as tuples_selected,
            n_tup_upd + n_tup_del + n_tup_ins as mod_tup_total
        -- we don't add _del and _upd here (already counted via seq_ & idx_)
        from pg_stat_user_tables s
            join pg_class c on c.oid = relid
    ),
    data2
    as
    (
                                    select
                0 as ord,
                '*** TOTAL ***' as table_name,
                null as schema_name,
                null as tblspace,
                sum(row_estimate) as row_estimate,
                sum(seq_tup_read) as seq_tup_read,
                sum(idx_tup_fetch) as idx_tup_fetch,
                -- wrong! sum(tuples_selected) as tuples_selected,
                sum(n_tup_ins) as n_tup_ins,
                sum(n_tup_del) as n_tup_del,
                sum(n_tup_upd) as n_tup_upd,
                sum(n_tup_hot_upd) as n_tup_hot_upd,
                avg(upd_hot_ratio) as upd_hot_ratio,
                sum(mod_tup_total) as mod_tup_total
            from data
        union all
            select
                1 as ord,
                '    tablespace: [' || coalesce(tblspace, 'pg_default') || ']' as table_name,
                null as schema_name,
                null, -- we don't need to pass real tblspace value for this aggregated record further
                sum(row_estimate) as row_estimate,
                sum(seq_tup_read) as seq_tup_read,
                sum(idx_tup_fetch) as idx_tup_fetch,
                -- wrong! sum(tuples_selected) as tuples_selected,
                sum(n_tup_ins) as n_tup_ins,
                sum(n_tup_del) as n_tup_del,
                sum(n_tup_upd) as n_tup_upd,
                sum(n_tup_hot_upd) as n_tup_hot_upd,
                avg(upd_hot_ratio) as upd_hot_ratio,
                sum(mod_tup_total) as mod_tup_total
            from data
            where (select count(distinct coalesce(tblspace, 'pg_default'))
            from data) > 1
            -- don't show this part if there are no custom tablespaces
            group by tblspace
        union all
            select 3, null, null, null, null, null, null, null, null, null, null, null, null
        union all
            select 4, table_name, schema_name, tblspace, row_estimate, seq_tup_read, idx_tup_fetch,
                -- wrong! tuples_selected,
                n_tup_ins, n_tup_del, n_tup_upd, n_tup_hot_upd, upd_hot_ratio, mod_tup_total
            from data
    )
select
    coalesce(nullif(schema_name, 'public') || '.', '') || table_name || coalesce(' [' || tblspace || ']', '') as "Table",
    '~' || case
    when row_estimate > 10^12 then round(row_estimate::numeric / 10^12::numeric, 0
)::text || 'T'
    when row_estimate > 10^9 then round
(row_estimate::numeric / 10^9::numeric, 0)::text || 'B'
    when row_estimate > 10^6 then round
(row_estimate::numeric / 10^6::numeric, 0)::text || 'M'
    when row_estimate > 10^3 then round
(row_estimate::numeric / 10^3::numeric, 0)::text || 'k'
    else row_estimate::text
end as "Rows",
(
with
    ops
    as
    (
        select *
        from data2 d2
        where d2.schema_name is not distinct from data2.schema_name and d2.table_name = data2.table_name
    ),
    ops_ratios(opname, ratio)
    as
    (
        /* wrong!! select
        'select',
        case when mod_tup_total > 0 then tuples_selected::numeric / mod_tup_total else 0 end
      from ops
      union all*/
                            select
                'insert',
                case when mod_tup_total > 0 then n_tup_ins::numeric / mod_tup_total else 0 end
            from ops
        union all
            select
                'delete',
                case when mod_tup_total > 0 then n_tup_del::numeric / mod_tup_total else 0 end
            from ops
        union all
            select
                'update',
                case when mod_tup_total > 0 then n_tup_upd::numeric / mod_tup_total else 0 end
            from ops
    )
select
    case
        when ratio > .7 then upper(opname) || ' ~' || round(100 * ratio, 2)::text || '%'
        else 'Mixed: ' || (
          select string_agg(upper(left(opname, 1)) || ' ~' || round(100 * ratio, 2)
::text || '%', ', ' order by ratio desc)
          from
(select *
from ops_ratios
where ratio > .2)
_
        )
end
    from ops_ratios
    order by ratio desc
    limit 1
  ) as "Write Load Type",
  mod_tup_total as "Tuples modified (I+U+D)",
  -- wrong!! tuples_selected as "SELECTed",
  n_tup_ins as "INSERTed",
  n_tup_del as "DELETEd",
  n_tup_upd as "UPDATEd",
  round
(100 * upd_hot_ratio, 2) as "HOT-updated, %",
  case when seq_tup_read + coalesce
(idx_tup_fetch, 0) > 0 then round
(100 * seq_tup_read::numeric /
(seq_tup_read + coalesce
(idx_tup_fetch, 0)), 2) else 0
end as "SeqScan, %"
from data2
order by ord, row_estimate desc;

--Current activity: count of current connections grouped by database, user name, state
select
    coalesce(usename, '** ALL users **') as "User",
    coalesce(datname, '** ALL databases **') as "DB",
    coalesce(state, '** ALL states **') as "Current State",
    count(*) as "Count",
    count(*) filter
(where state_change < now
() - interval '1 minute') as "State changed >1m ago",
  count
(*) filter
(where state_change < now
() - interval '1 hour') as "State changed >1h ago"
from pg_stat_activity
group by grouping sets
((datname, usename, state),
(usename, state),
())
order by
  usename is null desc,
  datname is null desc,
  2 asc,
  3 asc,
  count
(*) desc
;

--Tables and columns without stats (so bloat cannot be estimated)

--Created by PostgreSQL Experts https://github.com/pgexperts/pgx_scripts/blob/master/bloat/no_stats_table_check.sql

SELECT table_schema, table_name,
    ( pg_class.relpages = 0 ) AS is_empty,
    ( psut.relname IS NULL OR ( psut.last_analyze IS NULL and psut.last_autoanalyze IS NULL ) ) AS never_analyzed,
    array_agg(column_name::TEXT) as no_stats_columns
FROM information_schema.columns
    JOIN pg_class ON columns.table_name = pg_class.relname
        AND pg_class.relkind = 'r'
    JOIN pg_namespace ON pg_class.relnamespace = pg_namespace.oid
        AND nspname = table_schema
    LEFT OUTER JOIN pg_stats
    ON table_schema = pg_stats.schemaname
        AND table_name = pg_stats.tablename
        AND column_name = pg_stats.attname
    LEFT OUTER JOIN pg_stat_user_tables AS psut
        ON table_schema = psut.schemaname
        AND table_name = psut.relname
WHERE pg_stats.attname IS NULL
    AND table_schema NOT IN ('pg_catalog', 'information_schema')
GROUP BY table_schema, table_name, relpages, psut.relname, last_analyze, last_autoanalyze;

--Unused and rarely used indexes

--PostgreSQL Experts https://github.com/pgexperts/pgx_scripts/blob/master/indexes/unused_indexes.sql

WITH table_scans as (
    SELECT relid,
        tables.idx_scan + tables.seq_scan as all_scans,
        ( tables.n_tup_ins + tables.n_tup_upd + tables.n_tup_del ) as writes,
                pg_relation_size(relid) as table_size
        FROM pg_stat_user_tables as tables
),
all_writes as (
    SELECT sum(writes) as total_writes
    FROM table_scans
),
indexes as (
    SELECT idx_stat.relid, idx_stat.indexrelid,
        idx_stat.schemaname, idx_stat.relname as tablename,
        idx_stat.indexrelname as indexname,
        idx_stat.idx_scan,
        pg_relation_size(idx_stat.indexrelid) as index_bytes,
        indexdef ~* 'USING btree' AS idx_is_btree
    FROM pg_stat_user_indexes as idx_stat
        JOIN pg_index
            USING (indexrelid)
        JOIN pg_indexes as indexes
            ON idx_stat.schemaname = indexes.schemaname
                AND idx_stat.relname = indexes.tablename
                AND idx_stat.indexrelname = indexes.indexname
    WHERE pg_index.indisunique = FALSE
),
index_ratios AS (
SELECT schemaname, tablename, indexname,
    idx_scan, all_scans,
    round(( CASE WHEN all_scans = 0 THEN 0.0::NUMERIC
        ELSE idx_scan::NUMERIC/all_scans * 100 END),2) as index_scan_pct,
    writes,
    round((CASE WHEN writes = 0 THEN idx_scan::NUMERIC ELSE idx_scan::NUMERIC/writes END),2)
        as scans_per_write,
    pg_size_pretty(index_bytes) as index_size,
    pg_size_pretty(table_size) as table_size,
    idx_is_btree, index_bytes
    FROM indexes
    JOIN table_scans
    USING (relid)
),
index_groups AS (
SELECT 'Never Used Indexes' as reason, *, 1 as grp
FROM index_ratios
WHERE
    idx_scan = 0
    and idx_is_btree
UNION ALL
SELECT 'Low Scans, High Writes' as reason, *, 2 as grp
FROM index_ratios
WHERE
    scans_per_write <= 1
    and index_scan_pct < 10
    and idx_scan > 0
    and writes > 100
    and idx_is_btree
UNION ALL
SELECT 'Seldom Used Large Indexes' as reason, *, 3 as grp
FROM index_ratios
WHERE
    index_scan_pct < 5
    and scans_per_write > 1
    and idx_scan > 0
    and idx_is_btree
    and index_bytes > 100000000
UNION ALL
SELECT 'High-Write Large Non-Btree' as reason, index_ratios.*, 4 as grp
FROM index_ratios, all_writes
WHERE
    ( writes::NUMERIC / ( total_writes + 1 ) ) > 0.02
    AND NOT idx_is_btree
    AND index_bytes > 100000000
ORDER BY grp, index_bytes DESC )
SELECT 
    reason,
    schemaname as schema_name,
    tablename as table_name,
    indexname as index_name,
    index_scan_pct,
    scans_per_write,
    index_size,
    table_size,
    idx_scan,
    all_scans
FROM index_groups
;


--Redundant indexes

-- Use it to see redundant indexes list

-- This query doesn't need any additional extensions to be installed
-- (except plpgsql), and doesn't create anything (like views or smth)
-- -- so feel free to use it in your clouds (Heroku, AWS RDS, etc)

-- (Keep in mind, that on replicas, the whole picture of index usage
-- is usually very different from master).

with fk_indexes as (
  select
    n.nspname as schema_name,
    ci.relname as index_name,
    cr.relname as table_name,
    (confrelid::regclass)::text as fk_table_ref,
    array_to_string(indclass, ', ') as opclasses
  from pg_index i
  join pg_class ci on ci.oid = i.indexrelid and ci.relkind = 'i'
  join pg_class cr on cr.oid = i.indrelid and cr.relkind = 'r'
  join pg_namespace n on n.oid = ci.relnamespace
  join pg_constraint cn on cn.conrelid = cr.oid
  left join pg_stat_user_indexes si on si.indexrelid = i.indexrelid
  where
     contype = 'f'
     and i.indisunique is false
     and conkey is not null
     and ci.relpages > 0 -- raise for a DB with a lot of indexes
     and si.idx_scan < 10
),
-- Redundant indexes
index_data as (
  select
    *,
    (select string_agg(lpad(i, 3, '0'), ' ') from unnest(string_to_array(indkey::text, ' ')) i) as columns,
    array_to_string(indclass, ', ') as opclasses
  from pg_index i
  join pg_class ci on ci.oid = i.indexrelid and ci.relkind = 'i'
  where indisvalid = true and ci.relpages > 0 -- raise for a DD with a lot of indexes
), redundant_indexes as (
  select
    i2.indexrelid as index_id,
    tnsp.nspname AS schema_name,
    trel.relname AS table_name,
    pg_relation_size(trel.oid) as table_size_bytes,
    irel.relname AS index_name,
    am1.amname as access_method,
    (i1.indexrelid::regclass)::text as reason,
    i1.indexrelid as reason_index_id,
    pg_get_indexdef(i1.indexrelid) main_index_def,
    pg_size_pretty(pg_relation_size(i1.indexrelid)) main_index_size,
    pg_get_indexdef(i2.indexrelid) index_def,
    pg_relation_size(i2.indexrelid) index_size_bytes,
    s.idx_scan as index_usage,
    quote_ident(tnsp.nspname) as formated_schema_name,
    coalesce(nullif(quote_ident(tnsp.nspname), 'public') || '.', '') || quote_ident(irel.relname) as formated_index_name,
    quote_ident(trel.relname) AS formated_table_name,
    coalesce(nullif(quote_ident(tnsp.nspname), 'public') || '.', '') || quote_ident(trel.relname) as formated_relation_name,
    i2.opclasses
  from
    index_data as i1
    join index_data as i2 on (
        i1.indrelid = i2.indrelid -- same table
        and i1.indexrelid <> i2.indexrelid -- NOT same index
    )
    inner join pg_opclass op1 on i1.indclass[0] = op1.oid
    inner join pg_opclass op2 on i2.indclass[0] = op2.oid
    inner join pg_am am1 on op1.opcmethod = am1.oid
    inner join pg_am am2 on op2.opcmethod = am2.oid
    join pg_stat_user_indexes as s on s.indexrelid = i2.indexrelid
    join pg_class as trel on trel.oid = i2.indrelid
    join pg_namespace as tnsp on trel.relnamespace = tnsp.oid
    join pg_class as irel on irel.oid = i2.indexrelid
  where
    not i2.indisprimary -- index 1 is not primary
    and not ( -- skip if index1 is (primary or uniq) and is NOT (primary and uniq)
        i2.indisunique and not i1.indisprimary
    )
    and am1.amname = am2.amname -- same access type
    and i1.columns like (i2.columns || '%') -- index 2 includes all columns from index 1
    and i1.opclasses like (i2.opclasses || '%')
    -- index expressions is same
    and pg_get_expr(i1.indexprs, i1.indrelid) is not distinct from pg_get_expr(i2.indexprs, i2.indrelid)
    -- index predicates is same
    and pg_get_expr(i1.indpred, i1.indrelid) is not distinct from pg_get_expr(i2.indpred, i2.indrelid)
), redundant_indexes_fk as (
  select
    ri.*,
    (
      select count(1)
      from fk_indexes fi
      where
        fi.fk_table_ref = ri.table_name
        and fi.opclasses like (ri.opclasses || '%')
     ) > 0 as supports_fk
  from redundant_indexes ri
),
-- Cut recursive links
redundant_indexes_tmp_num as (
  select
    row_number() over () num,
    rig.*
  from redundant_indexes_fk rig
  order by index_id
), redundant_indexes_tmp_cut as (
  select
    ri1.*,
    ri2.num as r_num
  from redundant_indexes_tmp_num ri1
  left join redundant_indexes_tmp_num ri2 on ri2.reason_index_id = ri1.index_id and ri1.reason_index_id = ri2.index_id
  where ri1.num < ri2.num or ri2.num is null
), redundant_indexes_cut_grouped as (
  select
    distinct(num),
    *
  from redundant_indexes_tmp_cut
  order by index_size_bytes desc
), redundant_indexes_grouped as (
  select
    distinct(num),
    *
  from redundant_indexes_tmp_cut
  order by index_size_bytes desc
)
select
  schema_name,
  table_name,
  table_size_bytes,
  index_name,
  access_method,
  string_agg(distinct reason, ', ') as redundant_to,
  string_agg(main_index_def, ', ') as main_index_def,
  string_agg(main_index_size, ', ') as main_index_size,
  index_def,
  index_size_bytes,
  index_usage,
  supports_fk
from redundant_indexes_cut_grouped
group by
  index_id,
  schema_name,
  table_name,
  table_size_bytes,
  index_name,
  access_method,
  index_def,
  index_size_bytes,
  index_usage,
  supports_fk
order by index_size_bytes desc;

--FKs with Missing/Bad Indexes

--Created by PostgreSQL Experts https://github.com/pgexperts/pgx_scripts/blob/master/indexes/fk_no_index.sql

-- check for FKs where there is no matching index
-- on the referencing side
-- or a bad index

with fk_actions ( code, action ) as (
  values
('a', 'error'),
('r', 'restrict'),
('c', 'cascade'),
('n', 'set null'),
('d', 'set default')
), fk_list as
(
  select
    pg_constraint.oid as fkoid, conrelid, confrelid as parentid,
    conname,
    relname,
    nspname,
    fk_actions_update.action as update_action,
    fk_actions_delete.action as delete_action,
    conkey as key_cols
from pg_constraint
    join pg_class on conrelid = pg_class.oid
    join pg_namespace on pg_class.relnamespace = pg_namespace.oid
    join fk_actions as fk_actions_update on confupdtype = fk_actions_update.code
    join fk_actions as fk_actions_delete on confdeltype = fk_actions_delete.code
where contype = 'f'
)
, fk_attributes as
(
  select fkoid, conrelid, attname, attnum
from fk_list
    join pg_attribute on conrelid = attrelid and attnum = any(key_cols)
order by fkoid, attnum
), fk_cols_list as
(
  select fkoid, array_agg(attname) as cols_list
from fk_attributes
group by fkoid
)
, index_list as
(
  select
    indexrelid as indexid,
    pg_class.relname as indexname,
    indrelid,
    indkey,
    indpred
is not null as has_predicate,
    pg_get_indexdef
(indexrelid) as indexdef
  from pg_index
  join pg_class on indexrelid = pg_class.oid
  where indisvalid
), fk_index_match as
(
  select
    fk_list.*,
    indexid,
    indexname,
    indkey::int[]
as indexatts,
    has_predicate,
    indexdef,
    array_length
(key_cols, 1) as fk_colcount,
    array_length
(indkey,1) as index_colcount,
    round
(pg_relation_size
(conrelid)/
(1024^2)::numeric) as table_mb,
    cols_list
  from fk_list
  join fk_cols_list using
(fkoid)
  left join index_list on
    conrelid = indrelid
    and
(indkey::int2[])[0:(array_length(key_cols,1) -1)] operator
(pg_catalog.@>) key_cols

), fk_perfect_match as
(
  select fkoid
from fk_index_match
where
    (index_colcount - 1) <= fk_colcount
    and not has_predicate
    and indexdef like '%USING btree%'
)
, fk_index_check as
    (
        select 'no index' as issue, *, 1 as issue_sort
    from fk_index_match
    where indexid is null
union all
    select 'questionable index' as issue, *, 2
    from fk_index_match
    where
    indexid is not null
        and fkoid not in (select fkoid
        from fk_perfect_match)
)
, parent_table_stats as
(
  select
    fkoid,
    tabstats.relname as parent_name,
    (n_tup_ins + n_tup_upd + n_tup_del + n_tup_hot_upd) as parent_writes,
    round(pg_relation_size(parentid)/(1024^2)
::numeric) as parent_mb
  from pg_stat_user_tables as tabstats
  join fk_list on relid = parentid
), fk_table_stats as
(
  select
    fkoid,
    (n_tup_ins + n_tup_upd + n_tup_del + n_tup_hot_upd) as writes,
    seq_scan as table_scans
from pg_stat_user_tables as tabstats
    join fk_list on relid = conrelid
)
select
    nspname as schema_name,
    relname as table_name,
    conname as fk_name,
    issue,
    table_mb,
    writes,
    table_scans,
    parent_name,
    parent_mb,
    parent_writes,
    cols_list,
    indexdef
from fk_index_check
    join parent_table_stats using (fkoid)
    join fk_table_stats using (fkoid)  
where
  table_mb > 9
    and (
    writes > 1000
    or parent_writes > 1000
    or parent_mb > 10
  )
order by issue_sort, table_mb desc, table_name, fk_name;

--Invalid indexes

-- Use it to see invalid indexes list

-- This query doesn't need any additional extensions to be installed
-- (except plpgsql), and doesn't create anything (like views or smth)
-- -- so feel free to use it in your clouds (Heroku, AWS RDS, etc)

-- (Keep in mind, that on replicas, the whole picture of index usage
-- is usually very different from master).

select 
    coalesce(nullif(pn.nspname, 'public') || '.', '') || pct.relname as "relation_name",
    pci.relname as index_name,
    pn.nspname as schema_name,
    pct.relname as table_name,
    pg_size_pretty(pg_relation_size(pidx.indexrelid)) index_size,
    format(
      'DROP INDEX CONCURRENTLY %s; -- %s, table %s',
      pidx.indexrelid::regclass::text,
      'Invalid index',
      pct.relname) as drop_code,
    replace(
      format('%s; -- table %s', pg_get_indexdef(pidx.indexrelid), pct.relname),
      'CREATE INDEX',
      'CREATE INDEX CONCURRENTLY'
    ) as revert_code
from pg_index pidx
join pg_class as pci on pci.oid = pidx.indexrelid
join pg_class as pct on pct.oid = pidx.indrelid
left join pg_namespace pn on pn.oid = pct.relnamespace
where pidx.indisvalid = false;

--Cleanup unused and redundant indexes – DO & UNDO migration DDL

-- Use it to generate a database migration (e.g. RoR's db:migrate or Sqitch)
-- to drop unused and redundant indexes.

-- This query generates a set of `DROP INDEX` statements, that
-- can be used in your migration script. Also, it generates
-- `CREATE INDEX`, put them to revert/rollback migration script.

-- It is also a good idea to manually double check all indexes being dropped.
-- WARNING here: when you are dropping an index B which is redundant to some index A,
-- check that you don't drop the A itself at the same time (it can be in "unused").
-- So if B is "redundant" to A and A is "unused", the script will suggest
-- dropping both. If so, it is probably better to drop B and leave A.
-- -- in this case there is a chance that A will be used. If it will still be unused,
-- you will drop it during the next cleanup routine procedure.

-- This query doesn't need any additional extensions to be installed
-- (except plpgsql), and doesn't create anything (like views or smth)
-- -- so feel free to use it in your clouds (Heroku, AWS RDS, etc)

-- It also does't do anything except reading system catalogs and
-- printing NOTICEs, so you can easily run it on your
--  production *master* database.
-- (Keep in mind, that on replicas, the whole picture of index usage
-- is usually very different from master).

-- TODO: take into account type of index and opclass
-- TODO: schemas

with unused as (
  select
      format('unused (idx_scan: %s)', pg_stat_user_indexes.idx_scan)::text as reason,
      pg_stat_user_indexes.relname as table_name,
      pg_stat_user_indexes.schemaname || '.' || indexrelname::text as index_name,
      pg_stat_user_indexes.idx_scan,
      (coalesce(n_tup_ins, 0) + coalesce(n_tup_upd, 0) - coalesce(n_tup_hot_upd, 0) + coalesce(n_tup_del, 0)) as write_activity,
      pg_stat_user_tables.seq_scan,
      pg_stat_user_tables.n_live_tup,
      pg_get_indexdef(pg_index.indexrelid) as index_def,
      pg_size_pretty(pg_relation_size(pg_index.indexrelid::regclass)) as index_size,
      pg_index.indexrelid
  from pg_stat_user_indexes
  join pg_stat_user_tables
      on pg_stat_user_indexes.relid = pg_stat_user_tables.relid
  join pg_index
      ON pg_index.indexrelid = pg_stat_user_indexes.indexrelid
  where
      pg_stat_user_indexes.idx_scan = 0 /* < 10 or smth */
      and pg_index.indisunique is false
      and pg_stat_user_indexes.idx_scan::float/(coalesce(n_tup_ins,0)+coalesce(n_tup_upd,0)-coalesce(n_tup_hot_upd,0)+coalesce(n_tup_del,0)+1)::float<0.01
), index_data as (
  select
    *,
    indkey::text as columns,
    array_to_string(indclass, ', ') as opclasses
  from pg_index
), redundant as (
  select
    i2.indrelid::regclass::text as table_name,
    i2.indexrelid::regclass::text as index_name,
    am1.amname as access_method,
    format('redundant to index: %I', i1.indexrelid::regclass)::text as reason,
    pg_get_indexdef(i1.indexrelid) main_index_def,
    pg_get_indexdef(i2.indexrelid) index_def,
    pg_size_pretty(pg_relation_size(i2.indexrelid)) index_size,
    s.idx_scan as index_usage,
    i2.indexrelid
  from
    index_data as i1
    join index_data as i2 on (
        i1.indrelid = i2.indrelid /* same table */
        and i1.indexrelid <> i2.indexrelid /* NOT same index */
    )
    inner join pg_opclass op1 on i1.indclass[0] = op1.oid
    inner join pg_opclass op2 on i2.indclass[0] = op2.oid
    inner join pg_am am1 on op1.opcmethod = am1.oid
    inner join pg_am am2 on op2.opcmethod = am2.oid
    join pg_stat_user_indexes as s on s.indexrelid = i2.indexrelid
  where
    not i1.indisprimary -- index 1 is not primary
    and not ( -- skip if index1 is (primary or uniq) and is NOT (primary and uniq)
        (i1.indisprimary or i1.indisunique)
        and (not i2.indisprimary or not i2.indisunique)
    )
    and  am1.amname = am2.amname -- same access type
    and (
      i2.columns like (i1.columns || '%') -- index 2 includes all columns from index 1
      or i1.columns = i2.columns -- index1 and index 2 includes same columns
    )
    and (
      i2.opclasses like (i1.opclasses || '%')
      or i1.opclasses = i2.opclasses
    )
    -- index expressions are same
    and pg_get_expr(i1.indexprs, i1.indrelid) is not distinct from pg_get_expr(i2.indexprs, i2.indrelid)
    -- index predicates are same
    and pg_get_expr(i1.indpred, i1.indrelid) is not distinct from pg_get_expr(i2.indpred, i2.indrelid)
), together as (
  select reason, table_name, index_name, index_size, index_def, null as main_index_def, indexrelid
  from unused
  union all
  select reason, table_name, index_name, index_size, index_def, main_index_def, indexrelid
  from redundant
  where index_usage = 0
), droplines as (
  select format('DROP INDEX CONCURRENTLY %s; -- %s, %s, table %s', max(index_name), max(index_size), string_agg(reason, ', '), table_name) as line
  from together t1
  group by table_name, index_name
  order by table_name, index_name
), createlines as (
  select
    replace(
      format('%s; -- table %s', max(index_def), table_name),
      'CREATE INDEX',
      'CREATE INDEX CONCURRENTLY'
    )as line
  from together t2
  group by table_name, index_name
  order by table_name, index_name
)
select '-- DO migration: --' as run_in_separate_transactions
union all
select * from droplines
union all
select ''
union all
select '-- UNDO migration: --'
union all
select * from createlines;


--Lock trees (leightweight)

-- Source: https://github.com/dataegret/pg-utils/blob/master/sql/locktree.sql
-- The paths won't be precise but this query is very light and may be used quite frequently

with recursive l as (
  select pid, locktype, granted,
    array_position(array['accessshare','rowshare','rowexclusive','shareupdateexclusive','share','sharerowexclusive','exclusive','accessexclusive'], left(mode,-4)) m,
    row(locktype,database,relation,page,tuple,virtualxid,transactionid,classid,objid,objsubid) obj from pg_locks
), pairs as (
  select w.pid waiter, l.pid locker, l.obj, l.m
    from l w join l on l.obj is not distinct from w.obj and l.locktype=w.locktype and not l.pid=w.pid and l.granted
   where not w.granted
     and not exists ( select from l i where i.pid=l.pid and i.locktype=l.locktype and i.obj is not distinct from l.obj and i.m > l.m )
), leads as (
  select o.locker, 1::int lvl, count(*) q, array[locker] track, false as cycle from pairs o group by o.locker
  union all
  select i.locker, leads.lvl+1, (select count(*) from pairs q where q.locker=i.locker), leads.track||i.locker, i.locker=any(leads.track)
    from pairs i, leads where i.waiter=leads.locker and not cycle
), tree as (
  select locker pid,locker dad,locker root,case when cycle then track end dl, null::record obj,0 lvl,locker::text path,array_agg(locker) over () all_pids from leads o
   where (cycle and not exists (select from leads i where i.locker=any(o.track) and (i.lvl>o.lvl or i.q<o.q)))
      or (not cycle and not exists (select from pairs where waiter=o.locker) and not exists (select from leads i where i.locker=o.locker and i.lvl<o.lvl))
  union all
  select w.waiter pid,tree.pid,tree.root,case when w.waiter=any(tree.dl) then tree.dl end,w.obj,tree.lvl+1,tree.path||'.'||w.waiter,all_pids || array_agg(w.waiter) over ()
    from tree join pairs w on tree.pid=w.locker and not w.waiter = any ( all_pids )
)
select (clock_timestamp() - a.xact_start)::interval(0) as ts_age,
       (clock_timestamp() - a.state_change)::interval(0) as change_age,
       a.datname,a.usename,a.client_addr,
       --w.obj wait_on_object,
       tree.pid,replace(a.state, 'idle in transaction', 'idletx') state,
       lvl,(select count(*) from tree p where p.path ~ ('^'||tree.path) and not p.path=tree.path) blocked,
       case when tree.pid=any(tree.dl) then '!>' else repeat(' .', lvl) end||' '||trim(left(regexp_replace(a.query, e'\\s+', ' ', 'g'),100)) query
  from tree
  left join pairs w on w.waiter=tree.pid and w.locker=tree.dad
  join pg_stat_activity a using (pid)
  join pg_stat_activity r on r.pid=tree.root
 order by (now() - r.xact_start), path;

 --Lock trees, detailed (based on pg_blocking_pids())

-- Based on: https://gitlab.com/-/snippets/1890428
-- See also: https://postgres.ai/blog/20211018-postgresql-lock-trees

begin;

    set local statement_timeout
    to '100ms';

with recursive activity as
(
  select
    pg_blocking_pids(pid) blocked_by,
    *,
    age(clock_timestamp(), xact_start)
::interval
(0) as tx_age,
    age
(clock_timestamp
(), state_change)::interval
(0) as state_age
  from pg_stat_activity
  where state is distinct from 'idle'
), blockers as
(
  select
    array_agg(distinct c
order by c
) as pids
  from
(
    select unnest(blocked_by)
from activity
  )
as dt
(c)
), tree as
(
  select
    activity.*,
    1 as level,
    activity.pid as top_blocker_pid,
    array[activity.pid]
as path,
    array[activity.pid]::int[] as all_blockers_above
  from activity, blockers
  where
    array[pid] <@ blockers.pids
    and blocked_by = '{}'::int[]
  union all
select
    activity.*,
    tree.level + 1 as level,
    tree.top_blocker_pid,
    path || array[activity.pid]
as path,
    tree.all_blockers_above || array_agg
(activity.pid) over
() as all_blockers_above
  from activity, tree
  where
    not array[activity.pid] <@ tree.all_blockers_above
    and activity.blocked_by <> '{}'::int[]
    and activity.blocked_by <@ tree.all_blockers_above
)
select
    pid,
    blocked_by,
    tx_age,
    state_age,
    backend_xid as xid,
    backend_xmin as xmin,
    replace(state, 'idle in transaction', 'idletx') as state,
    datname,
    usename,
    wait_event_type || ':' || wait_event as wait,
    (select count(distinct t1.pid)
    from tree t1
    where array[tree.pid]
<@ t1.path and t1.pid <> tree.pid) as blkd,
  format
(
    '%s %s%s',
    lpad
('[' || pid::text || ']', 7, ' '),
    repeat
('.', level - 1) || case when level > 1 then ' '
end,
    left
(query, 1000)
  ) as query
from tree
order by top_blocker_pid, level, pid;

commit;

--Slowest queries, by total time (requires pg_stat_statements)

-- In pg_stat_statements, there is a problem: sometimes (quite often), it registers the same query twice (or even more).
-- It's easy to check in your DB:
--
--   with heh as (
--     select userid, dbid, query, count(*), array_agg(queryid) queryids
--     from pg_stat_statements group by 1, 2, 3 having count(*) > 1
--  ) select left(query, 85) || '...', userid, dbid, count, queryids from heh;
--
-- This query gives you "full picture", aggregating stats for each query-database-username ternary

-- Works with Postgres 9.6+

select
    sum(calls) as calls,
    \
if :postgres_dba_pgvers_13plus
  round
(sum
(total_exec_time)::numeric, 2) as total_exec_t,
  round
((sum
(mean_exec_time * calls) / sum
(calls))::numeric, 2) as mean_exec_t,
  format
(
    '%s–%s',
    round
(min
(min_exec_time)::numeric, 2), 
    round
(max
(max_exec_time)::numeric, 2)
  ) as min_max_exec_t,
  round
(sum
(total_plan_time)::numeric, 2) as total_plan_t,
  round
((sum
(mean_plan_time * calls) / sum
(calls))::numeric, 2) as mean_plan_t,
  format
(
    '%s–%s',
    round
(min
(min_plan_time)::numeric, 2), 
    round
(max
(max_plan_time)::numeric, 2)
  ) as min_max_plan_t,
\else
  sum
(calls) as calls,
  round
(sum
(total_time)::numeric, 2) as total_time,
  round
((sum
(mean_time * calls) / sum
(calls))::numeric, 2) as mean_time,
  format
(
    '%s–%s',
    round
(min
(min_time)::numeric, 2), 
    round
(max
(max_time)::numeric, 2)
  ) as min_max_t,
  -- stddev_time, -- https://stats.stackexchange.com/questions/55999/is-it-possible-to-find-the-combined-standard-deviation
\endif
  sum
(rows) as rows,
(select usename
from pg_user
where usesysid = userid)
as usr,
(select datname
from pg_database
where oid = dbid)
as db,
  query,
  sum
(shared_blks_hit) as shared_blks_hit,
  sum
(shared_blks_read) as shared_blks_read,
  sum
(shared_blks_dirtied) as shared_blks_dirtied,
  sum
(shared_blks_written) as shared_blks_written,
  sum
(local_blks_hit) as local_blks_hit,
  sum
(local_blks_read) as local_blks_read,
  sum
(local_blks_dirtied) as local_blks_dirtied,
  sum
(local_blks_written) as local_blks_written,
  sum
(temp_blks_read) as temp_blks_read,
  sum
(temp_blks_written) as temp_blks_written,
  sum
(blk_read_time) as blk_read_time,
  sum
(blk_write_time) as blk_write_time,
  array_agg
(queryid) as queryids -- 9.4+
from pg_stat_statements
group by userid, dbid, query
\
if :postgres_dba_pgvers_13plus
order by sum
(total_exec_time) desc
\else
order by sum
(total_time) desc
\endif
limit 50;

--Slowest queries report (requires pg_stat_statements)

--Original version – Data Egret: https://github.com/dataegret/pg-utils/blob/master/sql/global_reports/query_stat_total.sql
\if :postgres_dba_pgvers_13plus
with pg_stat_statements_slice as (
  select *
  from pg_stat_statements
  -- if current database is postgres then generate report for all databases,
  -- otherwise generate for current database only
  where
    current_database() = 'postgres'
    or dbid = (
      select oid
      from pg_database
      where datname = current_database()
    )
), pg_stat_statements_normalized as (
  select
    *,
    translate(
      regexp_replace(
        regexp_replace(
          regexp_replace(
            regexp_replace(
              query,
              e'\\?(::[a-zA-Z_]+)?( *, *\\?(::[a-zA-Z_]+)?)+', '?', 'g'
            ),
            e'\\$[0-9]+(::[a-zA-Z_]+)?( *, *\\$[0-9]+(::[a-zA-Z_]+)?)*', '$N', 'g'
          ),
          e'--.*$', '', 'ng'
        ),
        e'/\\*.*?\\*/', '', 'g'
      ),
      e'\r', ''
    ) as query_normalized
  from pg_stat_statements_slice
), totals as (
  select
    sum(total_exec_time) as total_exec_time,
    sum(blk_read_time+blk_write_time) as io_time,
    sum(total_exec_time-blk_read_time-blk_write_time) as non_io_time,
    sum(calls) as ncalls,
    sum(rows) as total_rows
  from pg_stat_statements_slice
), _pg_stat_statements as (
  select
    (select datname from pg_database where oid = p.dbid) as database,
    (select rolname from pg_roles where oid = p.userid) as username,
    --select shortest query, replace \n\n-- strings to avoid email clients format text as footer
    substring(
      translate(
        replace(
          (array_agg(query order by length(query)))[1],
          e'-- \n',
          e'--\n'
        ),
        e'\r', ''
      ),
      1,
      8192
    ) as query,
    sum(total_exec_time) as total_exec_time,
    sum(blk_read_time) as blk_read_time, sum(blk_write_time) as blk_write_time,
    sum(calls) as calls, sum(rows) as rows
  from pg_stat_statements_normalized p
  group by dbid, userid, md5(query_normalized)
), totals_readable as (
  select
    to_char(interval '1 millisecond' * total_exec_time, 'HH24:MI:SS') as total_exec_time,
    (100*io_time/total_exec_time)::numeric(20,2) as io_time_percent,
    to_char(ncalls, 'FM999,999,999,990') as total_queries,
    (select to_char(count(distinct md5(query)), 'FM999,999,990') from _pg_stat_statements) as unique_queries
  from totals
), statements as (
  select
    (100*total_exec_time/(select total_exec_time from totals)) as time_percent,
    (100*(blk_read_time+blk_write_time)/(select greatest(io_time, 1) from totals)) as io_time_percent,
    (100*(total_exec_time-blk_read_time-blk_write_time)/(select non_io_time from totals)) as non_io_time_percent,
    to_char(interval '1 millisecond' * total_exec_time, 'HH24:MI:SS') as total_exec_time,
    (total_exec_time::numeric/calls)::numeric(20,2) as avg_time,
    ((total_exec_time-blk_read_time-blk_write_time)::numeric/calls)::numeric(20, 2) as avg_non_io_time,
    ((blk_read_time+blk_write_time)::numeric/calls)::numeric(20, 2) as avg_io_time,
    to_char(calls, 'FM999,999,999,990') as calls,
    (100*calls/(select ncalls from totals))::numeric(20, 2) as calls_percent,
    to_char(rows, 'FM999,999,999,990') as rows,
    (100*rows/(select total_rows from totals))::numeric(20, 2) as row_percent,
    database,
    username,
    query
  from _pg_stat_statements
  where
    (total_exec_time-blk_read_time-blk_write_time)/(select non_io_time from totals) >= 0.01
    or (blk_read_time+blk_write_time)/(
      select greatest(io_time, 1) from totals
    ) >= 0.01
    or calls/(select ncalls from totals) >= 0.02
    or rows/(select total_rows from totals) >= 0.02
  union all
  select
    (100*sum(total_exec_time)::numeric/(select total_exec_time from totals)) as time_percent,
    (100*sum(blk_read_time+blk_write_time)::numeric/(select greatest(io_time, 1) from totals)) as io_time_percent,
    (100*sum(total_exec_time-blk_read_time-blk_write_time)::numeric/(select non_io_time from totals)) as non_io_time_percent,
    to_char(interval '1 millisecond' * sum(total_exec_time), 'HH24:MI:SS') as total_exec_time,
    (sum(total_exec_time)::numeric/sum(calls))::numeric(20,2) as avg_time,
    (sum(total_exec_time-blk_read_time-blk_write_time)::numeric/sum(calls))::numeric(20, 2) as avg_non_io_time,
    (sum(blk_read_time+blk_write_time)::numeric/sum(calls))::numeric(20, 2) as avg_io_time,
    to_char(sum(calls), 'FM999,999,999,990') as calls,
    (100*sum(calls)/(select ncalls from totals))::numeric(20, 2) as calls_percent,
    to_char(sum(rows), 'FM999,999,999,990') as rows,
    (100*sum(rows)/(select total_rows from totals))::numeric(20, 2) as row_percent,
    'all' as database,
    'all' as username,
    'other' as query
  from _pg_stat_statements
  where
    not (
      (total_exec_time-blk_read_time-blk_write_time)/(select non_io_time from totals) >= 0.01
      or (blk_read_time+blk_write_time)/(select greatest(io_time, 1) from totals) >= 0.01
      or calls/(select ncalls from totals)>=0.02 or rows/(select total_rows from totals) >= 0.02
    )
), statements_readable as (
  select row_number() over (order by s.time_percent desc) as pos,
    to_char(time_percent, 'FM990.0') || '%' as time_percent,
    to_char(io_time_percent, 'FM990.0') || '%' as io_time_percent,
    to_char(non_io_time_percent, 'FM990.0') || '%' as non_io_time_percent,
    to_char(avg_io_time*100/(coalesce(nullif(avg_time, 0), 1)), 'FM990.0') || '%' as avg_io_time_percent,
    total_exec_time, avg_time, avg_non_io_time, avg_io_time, calls, calls_percent, rows, row_percent,
    database, username, query
  from statements s
  where calls is not null
)
select
  e'total time:\t' || total_exec_time || ' (IO: ' || io_time_percent || E'%)\n'
  || e'total queries:\t' || total_queries || ' (unique: ' || unique_queries || E')\n'
  || 'report for ' || (select case when current_database() = 'postgres' then 'all databases' else current_database() || ' database' end)
  || E', version b0.9.6'
  || ' @ PostgreSQL '
  || (select setting from pg_settings where name='server_version') || E'\ntracking '
  || (select setting from pg_settings where name='pg_stat_statements.track') || ' '
  || (select setting from pg_settings where name='pg_stat_statements.max') || ' queries, utilities '
  || (select setting from pg_settings where name='pg_stat_statements.track_utility')
  || ', logging ' || (select (case when setting = '0' then 'all' when setting = '-1' then 'none' when setting::int > 1000 then (setting::numeric/1000)::numeric(20, 1) || 's+' else setting || 'ms+' end) from pg_settings where name='log_min_duration_statement')
  || E' queries\n'
  || (
    select coalesce(string_agg('WARNING: database ' || datname || ' must be vacuumed within ' || to_char(2147483647 - age(datfrozenxid), 'FM999,999,999,990') || ' transactions', E'\n' order by age(datfrozenxid) desc) || E'\n', '')
    from pg_database where (2147483647 - age(datfrozenxid)) < 200000000
  ) || E'\n'
from totals_readable
union all
(
select
  e'=============================================================================================================\n'
  || 'pos:' || pos || E'\t total time: ' || total_exec_time || ' (' || time_percent
  || ', IO: ' || io_time_percent || ', Non-IO: ' || non_io_time_percent || E')\t calls: '
  || calls || ' (' || calls_percent || E'%)\t avg_time: ' || avg_time
  || 'ms (IO: ' || avg_io_time_percent || E')\n' || 'user: '
  || username || E'\t db: ' || database || E'\t rows: ' || rows
  || ' (' || row_percent || '%)' || E'\t query:\n' || query || E'\n'
from statements_readable
order by pos
);

\else
with pg_stat_statements_slice as (
  select *
  from pg_stat_statements
  -- if current database is postgres then generate report for all databases,
  -- otherwise generate for current database only
  where
    current_database() = 'postgres'
    or dbid = (
      select oid
      from pg_database
      where datname = current_database()
    )
), pg_stat_statements_normalized as (
  select
    *,
    translate(
      regexp_replace(
        regexp_replace(
          regexp_replace(
            regexp_replace(
              query,
              e'\\?(::[a-zA-Z_]+)?( *, *\\?(::[a-zA-Z_]+)?)+', '?', 'g'
            ),
            e'\\$[0-9]+(::[a-zA-Z_]+)?( *, *\\$[0-9]+(::[a-zA-Z_]+)?)*', '$N', 'g'
          ),
          e'--.*$', '', 'ng'
        ),
        e'/\\*.*?\\*/', '', 'g'
      ),
      e'\r', ''
    ) as query_normalized
  from pg_stat_statements_slice
), totals as (
  select
    sum(total_time) as total_time,
    sum(blk_read_time+blk_write_time) as io_time,
    sum(total_time-blk_read_time-blk_write_time) as non_io_time,
    sum(calls) as ncalls,
    sum(rows) as total_rows
  from pg_stat_statements_slice
), _pg_stat_statements as (
  select
    (select datname from pg_database where oid = p.dbid) as database,
    (select rolname from pg_roles where oid = p.userid) as username,
    --select shortest query, replace \n\n-- strings to avoid email clients format text as footer
    substring(
      translate(
        replace(
          (array_agg(query order by length(query)))[1],
          e'-- \n',
          e'--\n'
        ),
        e'\r', ''
      ),
      1,
      8192
    ) as query,
    sum(total_time) as total_time,
    sum(blk_read_time) as blk_read_time, sum(blk_write_time) as blk_write_time,
    sum(calls) as calls, sum(rows) as rows
  from pg_stat_statements_normalized p
  group by dbid, userid, md5(query_normalized)
), totals_readable as (
  select
    to_char(interval '1 millisecond' * total_time, 'HH24:MI:SS') as total_time,
    (100*io_time/total_time)::numeric(20,2) as io_time_percent,
    to_char(ncalls, 'FM999,999,999,990') as total_queries,
    (select to_char(count(distinct md5(query)), 'FM999,999,990') from _pg_stat_statements) as unique_queries
  from totals
), statements as (
  select
    (100*total_time/(select total_time from totals)) as time_percent,
    (100*(blk_read_time+blk_write_time)/(select greatest(io_time, 1) from totals)) as io_time_percent,
    (100*(total_time-blk_read_time-blk_write_time)/(select non_io_time from totals)) as non_io_time_percent,
    to_char(interval '1 millisecond' * total_time, 'HH24:MI:SS') as total_time,
    (total_time::numeric/calls)::numeric(20,2) as avg_time,
    ((total_time-blk_read_time-blk_write_time)::numeric/calls)::numeric(20, 2) as avg_non_io_time,
    ((blk_read_time+blk_write_time)::numeric/calls)::numeric(20, 2) as avg_io_time,
    to_char(calls, 'FM999,999,999,990') as calls,
    (100*calls/(select ncalls from totals))::numeric(20, 2) as calls_percent,
    to_char(rows, 'FM999,999,999,990') as rows,
    (100*rows/(select total_rows from totals))::numeric(20, 2) as row_percent,
    database,
    username,
    query
  from _pg_stat_statements
  where
    (total_time-blk_read_time-blk_write_time)/(select non_io_time from totals) >= 0.01
    or (blk_read_time+blk_write_time)/(
      select greatest(io_time, 1) from totals
    ) >= 0.01
    or calls/(select ncalls from totals) >= 0.02
    or rows/(select total_rows from totals) >= 0.02
  union all
  select
    (100*sum(total_time)::numeric/(select total_time from totals)) as time_percent,
    (100*sum(blk_read_time+blk_write_time)::numeric/(select greatest(io_time, 1) from totals)) as io_time_percent,
    (100*sum(total_time-blk_read_time-blk_write_time)::numeric/(select non_io_time from totals)) as non_io_time_percent,
    to_char(interval '1 millisecond' * sum(total_time), 'HH24:MI:SS') as total_time,
    (sum(total_time)::numeric/sum(calls))::numeric(20,2) as avg_time,
    (sum(total_time-blk_read_time-blk_write_time)::numeric/sum(calls))::numeric(20, 2) as avg_non_io_time,
    (sum(blk_read_time+blk_write_time)::numeric/sum(calls))::numeric(20, 2) as avg_io_time,
    to_char(sum(calls), 'FM999,999,999,990') as calls,
    (100*sum(calls)/(select ncalls from totals))::numeric(20, 2) as calls_percent,
    to_char(sum(rows), 'FM999,999,999,990') as rows,
    (100*sum(rows)/(select total_rows from totals))::numeric(20, 2) as row_percent,
    'all' as database,
    'all' as username,
    'other' as query
  from _pg_stat_statements
  where
    not (
      (total_time-blk_read_time-blk_write_time)/(select non_io_time from totals) >= 0.01
      or (blk_read_time+blk_write_time)/(select greatest(io_time, 1) from totals) >= 0.01
      or calls/(select ncalls from totals)>=0.02 or rows/(select total_rows from totals) >= 0.02
    )
), statements_readable as (
  select row_number() over (order by s.time_percent desc) as pos,
    to_char(time_percent, 'FM990.0') || '%' as time_percent,
    to_char(io_time_percent, 'FM990.0') || '%' as io_time_percent,
    to_char(non_io_time_percent, 'FM990.0') || '%' as non_io_time_percent,
    to_char(avg_io_time*100/(coalesce(nullif(avg_time, 0), 1)), 'FM990.0') || '%' as avg_io_time_percent,
    total_time, avg_time, avg_non_io_time, avg_io_time, calls, calls_percent, rows, row_percent,
    database, username, query
  from statements s
  where calls is not null
)
select
  e'total time:\t' || total_time || ' (IO: ' || io_time_percent || E'%)\n'
  || e'total queries:\t' || total_queries || ' (unique: ' || unique_queries || E')\n'
  || 'report for ' || (select case when current_database() = 'postgres' then 'all databases' else current_database() || ' database' end)
  || E', version b0.9.6'
  || ' @ PostgreSQL '
  || (select setting from pg_settings where name='server_version') || E'\ntracking '
  || (select setting from pg_settings where name='pg_stat_statements.track') || ' '
  || (select setting from pg_settings where name='pg_stat_statements.max') || ' queries, utilities '
  || (select setting from pg_settings where name='pg_stat_statements.track_utility')
  || ', logging ' || (select (case when setting = '0' then 'all' when setting = '-1' then 'none' when setting::int > 1000 then (setting::numeric/1000)::numeric(20, 1) || 's+' else setting || 'ms+' end) from pg_settings where name='log_min_duration_statement')
  || E' queries\n'
  || (
    select coalesce(string_agg('WARNING: database ' || datname || ' must be vacuumed within ' || to_char(2147483647 - age(datfrozenxid), 'FM999,999,999,990') || ' transactions', E'\n' order by age(datfrozenxid) desc) || E'\n', '')
    from pg_database where (2147483647 - age(datfrozenxid)) < 200000000
  ) || E'\n'
from totals_readable
union all
(
select
  e'=============================================================================================================\n'
  || 'pos:' || pos || E'\t total time: ' || total_time || ' (' || time_percent
  || ', IO: ' || io_time_percent || ', Non-IO: ' || non_io_time_percent || E')\t calls: '
  || calls || ' (' || calls_percent || E'%)\t avg_time: ' || avg_time
  || 'ms (IO: ' || avg_io_time_percent || E')\n' || 'user: '
  || username || E'\t db: ' || database || E'\t rows: ' || rows
  || ' (' || row_percent || '%)' || E'\t query:\n' || query || E'\n'
from statements_readable
order by pos
);
\endif

--Postgres parameters tuning

-- For Postgres versions older than 10, copy/paste the part
-- below the last "\else" (scroll down)

\set postgres_dba_t1_error false
\if :postgres_dba_interactive_mode
\echo
\echo 'What is the type of your database?'
\echo '  1 – OLTP, Web/Mobile App'
\echo '  2 – Analytics, Data Warehouse'
\echo '  3 – Mixed Load'
\echo '  4 - Desktop / Developer''s Machine'
\echo 'Type your choice and press <Enter>: '
\prompt postgres_dba_t1_instance_type

select :postgres_dba_t1_instance_type = 1 as postgres_dba_t1_instance_type_oltp \gset
select :postgres_dba_t1_instance_type = 2 as postgres_dba_t1_instance_type_analytics \gset
select :postgres_dba_t1_instance_type = 3 as postgres_dba_t1_instance_type_mixed \gset
select :postgres_dba_t1_instance_type = 4 as postgres_dba_t1_instance_type_desktop \gset

\echo
\echo
\echo 'Where is the instance located?'
\echo '  1 – On-premise'
\echo '  2 – Amazon EC2'
\echo '  3 – Amazon RDS'
\echo 'Type your choice and press <Enter>: '
\prompt postgres_dba_t1_location

select :postgres_dba_t1_location = 1 as postgres_dba_t1_location_onpremise \gset
select :postgres_dba_t1_location = 2 as postgres_dba_t1_location_ec2 \gset
select :postgres_dba_t1_location = 3 as postgres_dba_t1_location_rds \gset

\echo
\echo

\if :postgres_dba_t1_location_onpremise
-- More questions to get number of CPU cores, RAM, disks
\echo 'Type number of CPU cores: '
\prompt postgres_dba_t1_cpu

\echo
\echo
\echo 'Type total available memory (in GB): '
\prompt postgres_dba_t1_memory

\echo
\echo
\echo 'Hard drive type?'
\echo '  1 - HDD storage'
\echo '  2 - SSD storage'
\echo 'Type your choice and press <Enter>: '
\prompt postgres_dba_t1_location

\elif :postgres_dba_t1_location_ec2
-- CPU/memory/disk is known (AWS EC2)
\elif :postgres_dba_t1_location_rds
-- CPU/memory/disk is known (AWS RDS)
\else
\echo Error! Impossible option.
\set postgres_dba_t1_error true
\endif

\endif

\if :postgres_dba_t1_error
\echo You put incorrect input, cannot proceed with this report. Press <Enter> to return to the menu
\prompt
\else
select
  name as "Parameter",
  case when setting in ('-1', '0', 'off', 'on') then setting else
    case unit
      when '8kB' then pg_size_pretty(setting::int8 * 8 * 1024)
      when '16MB' then pg_size_pretty(setting::int8 * 16 * 1024 * 1024)
      when 'kB' then pg_size_pretty(setting::int8 * 1024)
      else setting || coalesce ('', ' ' || unit)
    end
  end as "Value",
  case when boot_val in ('-1', '0', 'off', 'on') then boot_val else
    case unit
      when '8kB' then pg_size_pretty(boot_val::int8 * 8 * 1024)
      when '16MB' then pg_size_pretty(boot_val::int8 * 16 * 1024 * 1024)
      when 'kB' then pg_size_pretty(boot_val::int8 * 1024)
      else boot_val || coalesce ('', ' ' || unit)
    end
  end as "Default",
  category as "Category"
from pg_settings
where
  name in (
    'max_connections',
    'shared_buffers',
    'effective_cache_size',
    'maintenance_work_mem',
    'work_mem',
    'min_wal_size',
    'max_wal_size',
    'checkpoint_completion_target',
    'wal_buffers',
    'default_statistics_target',
    'random_page_cost',
    'effective_io_concurrency',
    'max_worker_processes',
    'max_parallel_workers_per_gather',
    'max_parallel_workers',
    'autovacuum_analyze_scale_factor',
    'autovacuum_max_workers',
    'autovacuum_vacuum_scale_factor',
    'autovacuum_work_mem',
    'autovacuum_naptime',
    'random_page_cost',
    'seq_page_cost'
  )
order by category, name;
\endif

--Vacuum: current activity

-- Based on: https://github.com/lesovsky/uber-scripts/blob/master/postgresql/sql/vacuum_activity.sql
with data as (
  select
    p.pid as pid,
    (select spcname from pg_tablespace where oid = reltablespace) as tblspace,
    p.datname as database,
    nspname as schema_name,
    relname as table_name,
    (now() - a.xact_start) as duration,
    coalesce(wait_event_type ||'.'|| wait_event, null) as waiting,
    case
      when a.query ~* '^autovacuum.*to prevent wraparound' then 'wraparound'
      when a.query ~* '^vacuum' then 'user'
      else 'auto'
    end as mode,
    p.phase,
    pg_size_pretty(pg_total_relation_size(relid)) as total_size,
    pg_size_pretty(pg_total_relation_size(relid) - pg_indexes_size(relid)) as table_size,
    pg_size_pretty(pg_indexes_size(relid)) as index_size,
    pg_size_pretty(p.heap_blks_scanned * current_setting('block_size')::int) as scanned,
    pg_size_pretty(p.heap_blks_vacuumed * current_setting('block_size')::int) as vacuumed,
    round(100.0 * p.heap_blks_scanned / p.heap_blks_total, 2) as scanned_pct,
    round(100.0 * p.heap_blks_vacuumed / p.heap_blks_total, 2) as vacuumed_pct,
    p.index_vacuum_count,
    round(100.0 * p.num_dead_tuples / p.max_dead_tuples, 2) as dead_pct,
    p.num_dead_tuples,
    p.max_dead_tuples
  from pg_stat_progress_vacuum p
  left join pg_stat_activity a using (pid)
  left join pg_class c on c.oid = p.relid
  left join pg_namespace n on n.oid = c.relnamespace
)
select
  pid as "PID",
  duration::interval(0)::text as "Duration",
  mode as "Mode",
  database || coalesce(
    e'\n' || coalesce(nullif(schema_name, 'public') || '.', '') || table_name || coalesce(' [' || tblspace || ']', ''),
    ''
  ) as "DB & Table",
  table_size as "Table",
  index_size as "Indexes",
  waiting as "Wait",
  phase as "Phase",
  scanned || ' (' || scanned_pct || '%)' || e' scanned\n'
    || vacuumed || ' (' || vacuumed_pct || '%) vacuumed' as "Heap Vacuuming",
  index_vacuum_count || ' completed cycles,'
    || e'\n'
    || case
      when num_dead_tuples > 10^12 then round(num_dead_tuples::numeric / 10^12::numeric, 0)::text || 'T'
      when num_dead_tuples > 10^9 then round(num_dead_tuples::numeric / 10^9::numeric, 0)::text || 'B'
      when num_dead_tuples > 10^6 then round(num_dead_tuples::numeric / 10^6::numeric, 0)::text || 'M'
      when num_dead_tuples > 10^3 then round(num_dead_tuples::numeric / 10^3::numeric, 0)::text || 'k'
      else num_dead_tuples::text
    end
    || ' (' || dead_pct || e'%) dead tuples\nof max ~'
    || case
      when max_dead_tuples > 10^12 then round(max_dead_tuples::numeric / 10^12::numeric, 0)::text || 'T'
      when max_dead_tuples > 10^9 then round(max_dead_tuples::numeric / 10^9::numeric, 0)::text || 'B'
      when max_dead_tuples > 10^6 then round(max_dead_tuples::numeric / 10^6::numeric, 0)::text || 'M'
      when max_dead_tuples > 10^3 then round(max_dead_tuples::numeric / 10^3::numeric, 0)::text || 'k'
      else max_dead_tuples::text
    end
    || ' collected now' as "Index Vacuuming"
from data
order by duration desc;

--Vacuum: VACUUM progress and autovacuum queue

-- Based on: https://gitlab.com/snippets/1889668

with table_opts as (
  select
    pg_class.oid,
    relname,
    nspname,
    array_to_string(reloptions, '') as relopts
  from pg_class
  join pg_namespace ns on relnamespace = ns.oid
), vacuum_settings as (
  select
    oid,
    relname,
    nspname,
    case
      when relopts like '%autovacuum_vacuum_threshold%' then regexp_replace(relopts, '.*autovacuum_vacuum_threshold=([0-9.]+).*', E'\\1')::int8
      else current_setting('autovacuum_vacuum_threshold')::int8
    end as autovacuum_vacuum_threshold,
    case
      when relopts like '%autovacuum_vacuum_scale_factor%' then regexp_replace(relopts, '.*autovacuum_vacuum_scale_factor=([0-9.]+).*', E'\\1')::numeric
      else current_setting('autovacuum_vacuum_scale_factor')::numeric
    end as autovacuum_vacuum_scale_factor,
    case when relopts ~ 'autovacuum_enabled=(false|off)' then false else true end as autovacuum_enabled
  from table_opts
), p as (
  select *
  from pg_stat_progress_vacuum
)
select
  --vacuum_settings.oid,
  coalesce(
    coalesce(nullif(vacuum_settings.nspname, 'public') || '.', '') || vacuum_settings.relname, -- current DB
    format('[something in "%I"]', p.datname)
  ) as table,
  round((100 * psat.n_dead_tup::numeric / nullif(pg_class.reltuples, 0))::numeric, 2) as dead_tup_pct,
  pg_class.reltuples::numeric,
  psat.n_dead_tup,
  'vt: ' || vacuum_settings.autovacuum_vacuum_threshold
    || ', vsf: ' || vacuum_settings.autovacuum_vacuum_scale_factor
    || case when not autovacuum_enabled then ', DISABLED' else ', enabled' end as "effective_settings",
  case
    when last_autovacuum > coalesce(last_vacuum, '0001-01-01') then left(last_autovacuum::text, 19) || ' (auto)'
    when last_vacuum is not null then left(last_vacuum::text, 19) || ' (manual)'
    else null
  end as "last_vacuumed",
  coalesce(p.phase, '~~~ in queue ~~~') as status,
  p.pid as pid,
  case
    when a.query ~ '^autovacuum.*to prevent wraparound' then 'wraparound'
    when a.query ~ '^vacuum' then 'user'
    when a.pid is null then null
    else 'regular'
  end as mode,
  case when a.pid is null then null else coalesce(wait_event_type ||'.'|| wait_event, 'f') end as waiting,
  round(100.0 * p.heap_blks_scanned / nullif(p.heap_blks_total, 0), 1) AS scanned_pct,
  round(100.0 * p.heap_blks_vacuumed / nullif(p.heap_blks_total, 0), 1) AS vacuumed_pct,
  p.index_vacuum_count,
  case
    when psat.relid is not null and p.relid is not null then
      (select count(*) from pg_index where indrelid = psat.relid)
    else null
  end as index_count
from pg_stat_all_tables psat
join pg_class on psat.relid = pg_class.oid
join vacuum_settings on pg_class.oid = vacuum_settings.oid
full outer join p on p.relid = psat.relid and p.datname = current_database()
left join pg_stat_activity a using (pid)
where
  psat.relid is null
  or autovacuum_vacuum_threshold + (autovacuum_vacuum_scale_factor::numeric * pg_class.reltuples) < psat.n_dead_tup;

  --Replication Slot Activity Slot
  SELECT
    r.slot_name,
    r.slot_type,
    r.plugin,
    r.database,
    a.usename,
    a.client_addr,
    a.wait_event_type ||'.'|| a.wait_event AS await,
    a.state,
    r.active,
    r.active_pid,
    coalesce(r.catalog_xmin,'NULL') ||'/'|| coalesce(r.xmin,'NULL') as horizon,
    greatest(age(r.catalog_xmin),age(r.xmin)) as horizon_age,
    pg_size_pretty(pg_xlog_location_diff(pg_current_xlog_location(), r.restart_lsn)) as restart_lsn_diff,
    pg_size_pretty(pg_xlog_location_diff(pg_current_xlog_location(), r.confirmed_flush_lsn)) not_received
FROM pg_replication_slots r
    LEFT JOIN pg_stat_activity a ON r.active_pid = a.pid
ORDER BY horizon_age DESC;

--autovacum queue detail
WITH
    table_opts
    AS
    (
        SELECT
            c.oid, c.relname, c.relfrozenxid, c.relminmxid, n.nspname, array_to_string(c.reloptions, '') AS relopts
        FROM pg_class c
            INNER JOIN pg_namespace n ON c.relnamespace = n.oid
        WHERE c.relkind IN ('r', 't') AND n.nspname NOT IN ('pg_catalog', 'information_schema') AND n.nspname !~ '^pg_temp'
    ),
    vacuum_settings
    AS
    (
        SELECT
            oid, relname, nspname, relfrozenxid, relminmxid,
            CASE
        WHEN relopts LIKE '%autovacuum_vacuum_threshold%'
        THEN regexp_replace(relopts, '.*autovacuum_vacuum_threshold=([0-9.]+).*', E'\\1'
    )::integer
        ELSE current_setting
('autovacuum_vacuum_threshold')::integer
END AS autovacuum_vacuum_threshold,
    CASE
        WHEN relopts LIKE '%autovacuum_vacuum_scale_factor%'
        THEN regexp_replace
(relopts, '.*autovacuum_vacuum_scale_factor=([0-9.]+).*', E'\\1')::real
        ELSE current_setting
('autovacuum_vacuum_scale_factor')::real
END AS autovacuum_vacuum_scale_factor,
    CASE
        WHEN relopts LIKE '%autovacuum_analyze_threshold%'
        THEN regexp_replace
(relopts, '.*autovacuum_analyze_threshold=([0-9.]+).*', E'\\1')::integer
        ELSE current_setting
('autovacuum_analyze_threshold')::integer
END AS autovacuum_analyze_threshold,
    CASE
        WHEN relopts LIKE '%autovacuum_analyze_scale_factor%'
        THEN regexp_replace
(relopts, '.*autovacuum_analyze_scale_factor=([0-9.]+).*', E'\\1')::real
        ELSE current_setting
('autovacuum_analyze_scale_factor')::real
END AS autovacuum_analyze_scale_factor,
    CASE
        WHEN relopts LIKE '%autovacuum_freeze_max_age%'
        THEN least
(regexp_replace
(relopts, '.*autovacuum_freeze_max_age=([0-9.]+).*', E'\\1')::bigint,current_setting
('autovacuum_freeze_max_age')::bigint)
        ELSE current_setting
('autovacuum_freeze_max_age')::bigint
END AS autovacuum_freeze_max_age,
    CASE
        WHEN relopts LIKE '%autovacuum_multixact_freeze_max_age%'
        THEN least
(regexp_replace
(relopts, '.*autovacuum_multixact_freeze_max_age=([0-9.]+).*', E'\\1')::bigint,current_setting
('autovacuum_multixact_freeze_max_age')::bigint)
        ELSE current_setting
('autovacuum_multixact_freeze_max_age')::bigint
END AS autovacuum_multixact_freeze_max_age
    FROM table_opts
)
SELECT
    s.schemaname ||'.'|| s.relname,
    CASE
        WHEN v.autovacuum_vacuum_threshold + (v.autovacuum_vacuum_scale_factor::numeric * c.reltuples) < s.n_dead_tup
        THEN true
        ELSE false
    END AS need_vacuum,
    CASE
        WHEN v.autovacuum_analyze_threshold + (v.autovacuum_analyze_scale_factor::numeric * c.reltuples) < s.n_mod_since_analyze
        THEN true
        ELSE false
    END AS need_analyze,
    CASE
        WHEN (age(v.relfrozenxid)::bigint > v.autovacuum_freeze_max_age) OR (mxid_age(v.relminmxid)::bigint
> v.autovacuum_multixact_freeze_max_age) 
        THEN true
        ELSE false
END AS need_wraparound
--    count(*)
FROM pg_stat_user_tables s
INNER JOIN pg_class c ON s.relid = c.oid
INNER JOIN vacuum_settings v ON c.oid = v.oid
WHERE
(v.autovacuum_vacuum_threshold +
(v.autovacuum_vacuum_scale_factor::numeric * c.reltuples) < s.n_dead_tup) 
OR
(v.autovacuum_analyze_threshold +
(v.autovacuum_analyze_scale_factor::numeric * c.reltuples) < s.n_mod_since_analyze)
OR
(age
(v.relfrozenxid)::bigint > v.autovacuum_freeze_max_age) OR
(mxid_age
(v.relminmxid)::bigint > v.autovacuum_multixact_freeze_max_age)
--GROUP BY 1,2,3 ORDER BY 4 DESC

--Table/index bloat size
-- show table and index bloat. 
-- author: Josh Berkus
WITH btree_index_atts AS (
    SELECT nspname, relname, reltuples, relpages, indrelid, relam,
        regexp_split_to_table(indkey::text, ' ')::smallint AS attnum,
        indexrelid as index_oid
    FROM pg_index
    JOIN pg_class ON pg_class.oid=pg_index.indexrelid
    JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace
    JOIN pg_am ON pg_class.relam = pg_am.oid
    WHERE pg_am.amname = 'btree'
    ),
index_item_sizes AS (
    SELECT
    i.nspname, i.relname, i.reltuples, i.relpages, i.relam,
    s.starelid, a.attrelid AS table_oid, index_oid,
    current_setting('block_size')::numeric AS bs,
    /* MAXALIGN: 4 on 32bits, 8 on 64bits (and mingw32 ?) */
    CASE
        WHEN version() ~ 'mingw32' OR version() ~ '64-bit' THEN 8
        ELSE 4
    END AS maxalign,
    24 AS pagehdr,
    /* per tuple header: add index_attribute_bm if some cols are null-able */
    CASE WHEN max(coalesce(s.stanullfrac,0)) = 0
        THEN 2
        ELSE 6
    END AS index_tuple_hdr,
    /* data len: we remove null values save space using it fractionnal part from stats */
    sum( (1-coalesce(s.stanullfrac, 0)) * coalesce(s.stawidth, 2048) ) AS nulldatawidth
    FROM pg_attribute AS a
    JOIN pg_statistic AS s ON s.starelid=a.attrelid AND s.staattnum = a.attnum
    JOIN btree_index_atts AS i ON i.indrelid = a.attrelid AND a.attnum = i.attnum
    WHERE a.attnum > 0
    GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9
),
index_aligned AS (
    SELECT maxalign, bs, nspname, relname AS index_name, reltuples,
        relpages, relam, table_oid, index_oid,
      ( 2 +
          maxalign - CASE /* Add padding to the index tuple header to align on MAXALIGN */
            WHEN 2%maxalign = 0 THEN maxalign
            ELSE 2%maxalign
          END
        + nulldatawidth + maxalign - CASE /* Add padding to the data to align on MAXALIGN */
            WHEN nulldatawidth::integer%maxalign = 0 THEN maxalign
            ELSE nulldatawidth::integer%maxalign
          END
      )::numeric AS nulldatahdrwidth, pagehdr
    FROM index_item_sizes AS s1
),
otta_calc AS (
  SELECT bs, nspname, table_oid, index_oid, index_name, relpages, coalesce(
    ceil((reltuples*(4+nulldatahdrwidth))/(bs-pagehdr::float)) +
      CASE WHEN am.amname IN ('hash','btree') THEN 1 ELSE 0 END , 0 -- btree and hash have a metadata reserved block
    ) AS otta
  FROM index_aligned AS s2
    LEFT JOIN pg_am am ON s2.relam = am.oid
),
raw_bloat AS (
    SELECT current_database() as dbname, nspname, c.relname AS table_name, index_name,
        bs*(sub.relpages)::bigint AS totalbytes,
        CASE
            WHEN sub.relpages <= otta THEN 0
            ELSE bs*(sub.relpages-otta)::bigint END
            AS wastedbytes,
        CASE
            WHEN sub.relpages <= otta
            THEN 0 ELSE bs*(sub.relpages-otta)::bigint * 100 / (bs*(sub.relpages)::bigint) END
            AS realbloat,
        pg_relation_size(sub.table_oid) as table_bytes,
        stat.idx_scan as index_scans
    FROM otta_calc AS sub
    JOIN pg_class AS c ON c.oid=sub.table_oid
    JOIN pg_stat_user_indexes AS stat ON sub.index_oid = stat.indexrelid
)
SELECT dbname as database_name, nspname as schema_name, table_name, index_name,
        round(realbloat, 1) as bloat_pct,
        wastedbytes as bloat_bytes, pg_size_pretty(wastedbytes) as bloat_size,
        totalbytes as index_bytes, pg_size_pretty(totalbytes) as index_size,
        table_bytes, pg_size_pretty(table_bytes) as table_size,
        index_scans
FROM raw_bloat
WHERE ( realbloat > 50 and wastedbytes > 50000000 )
ORDER BY wastedbytes DESC;

--constraint detils
SELECT
    conname AS constraint,
    CASE
        WHEN contype = 'c' THEN 'check'
        WHEN contype = 'f' THEN 'foreign'
        WHEN contype = 'p' THEN 'primary'
        WHEN contype = 'u' THEN 'unique'
        WHEN contype = 't' THEN 'trigger'
        WHEN contype = 'x' THEN 'excliusion'
    END AS type,
    connamespace::regnamespace
AS schema, conrelid::regclass AS relation,
    array
(SELECT attname
FROM pg_attribute
WHERE attrelid = conrelid::regclass AND attnum = any(conkey)
) AS attributes,
    confrelid::regclass AS foreign_realtion,
    array
(SELECT attname
FROM pg_attribute
WHERE attrelid = confrelid::regclass AND attnum = any(confkey)
) AS foreign_attributes
FROM pg_constraint;

--view dependency
-- show table's dependent views (DROP VIEW -> ALTER TABLE -> CREATE VIEW)
-- don't forget edit WHERE conditions
SELECT dependent_ns.nspname as dependent_schema
, dependent_view.relname as dependent_view 
, source_ns.nspname as source_schema
, source_table.relname as source_table
, pg_attribute.attname as column_name
FROM pg_depend
    JOIN pg_rewrite ON pg_depend.objid = pg_rewrite.oid
    JOIN pg_class as dependent_view ON pg_rewrite.ev_class = dependent_view.oid
    JOIN pg_class as source_table ON pg_depend.refobjid = source_table.oid
    JOIN pg_attribute ON pg_depend.refobjid = pg_attribute.attrelid
        AND pg_depend.refobjsubid = pg_attribute.attnum
    JOIN pg_namespace dependent_ns ON dependent_ns.oid = dependent_view.relnamespace
    JOIN pg_namespace source_ns ON source_ns.oid = source_table.relnamespace
WHERE 
source_ns.nspname = 'my_schema'
    AND source_table.relname = 'my_table'
    AND pg_attribute.attnum > 0
    AND pg_attribute.attname = 'my_column'
ORDER BY 1,2;

--IndexUsage
-- Author: Josh Berkus
-- url: https://gist.github.com/jberkus/6b1bcaf7724dfc2a54f3
WITH table_scans as (
    SELECT relid,
        tables.idx_scan + tables.seq_scan as all_scans,
        ( tables.n_tup_ins + tables.n_tup_upd + tables.n_tup_del ) as writes,
                pg_relation_size(relid) as table_size
        FROM pg_stat_user_tables as tables
),
all_writes as (
    SELECT sum(writes) as total_writes
    FROM table_scans
),
indexes as (
    SELECT idx_stat.relid, idx_stat.indexrelid,
        idx_stat.schemaname, idx_stat.relname as tablename,
        idx_stat.indexrelname as indexname,
        idx_stat.idx_scan,
        pg_relation_size(idx_stat.indexrelid) as index_bytes,
        indexdef ~* 'USING btree' AS idx_is_btree
    FROM pg_stat_user_indexes as idx_stat
        JOIN pg_index
            USING (indexrelid)
        JOIN pg_indexes as indexes
            ON idx_stat.schemaname = indexes.schemaname
                AND idx_stat.relname = indexes.tablename
                AND idx_stat.indexrelname = indexes.indexname
    WHERE pg_index.indisunique = FALSE
),
index_ratios AS (
SELECT schemaname, tablename, indexname,
    idx_scan, all_scans,
    round(( CASE WHEN all_scans = 0 THEN 0.0::NUMERIC
        ELSE idx_scan::NUMERIC/all_scans * 100 END),2) as index_scan_pct,
    writes,
    round((CASE WHEN writes = 0 THEN idx_scan::NUMERIC ELSE idx_scan::NUMERIC/writes END),2)
        as scans_per_write,
    pg_size_pretty(index_bytes) as index_size,
    pg_size_pretty(table_size) as table_size,
    idx_is_btree, index_bytes
    FROM indexes
    JOIN table_scans
    USING (relid)
),
index_groups AS (
SELECT 'Never Used Indexes' as reason, *, 1 as grp
FROM index_ratios
WHERE
    idx_scan = 0
    and idx_is_btree
UNION ALL
SELECT 'Low Scans, High Writes' as reason, *, 2 as grp
FROM index_ratios
WHERE
    scans_per_write <= 1
    and index_scan_pct < 10
    and idx_scan > 0
    and writes > 100
    and idx_is_btree
UNION ALL
SELECT 'Seldom Used Large Indexes' as reason, *, 3 as grp
FROM index_ratios
WHERE
    index_scan_pct < 5
    and scans_per_write > 1
    and idx_scan > 0
    and idx_is_btree
    and index_bytes > 100000000
UNION ALL
SELECT 'High-Write Large Non-Btree' as reason, index_ratios.*, 4 as grp 
FROM index_ratios, all_writes
WHERE
    ( writes::NUMERIC / total_writes ) > 0.02
    AND NOT idx_is_btree
    AND index_bytes > 100000000
ORDER BY grp, index_bytes DESC )
SELECT reason, schemaname, tablename, indexname,
    index_scan_pct, scans_per_write, index_size, table_size
FROM index_groups;

--Wraparound
-- Check relations with risk of wraparound.
-- Look at 'to_limit', as 'to_limit' values closer to zero, as sooner wraparound will occur.

SELECT
    c.oid::regclass AS relname,
    age(c.relfrozenxid) AS xid_age,
    to_char(2147483647 - age(c.relfrozenxid), 'FM999,999,999,990') AS to_limit,
    pg_size_pretty(pg_total_relation_size(c.oid)) AS total_size,
    CASE WHEN n_live_tup > 0 THEN round(n_dead_tup * 100.0 / n_live_tup, 2) END AS "dead_tup_%",
    now() - coalesce(pg_stat_get_last_autovacuum_time(c.oid), pg_stat_get_last_vacuum_time(c.oid)) AS last_vacuumed
FROM pg_class c
    LEFT JOIN pg_stat_user_tables s ON s.relid=c.oid
WHERE c.relkind IN ('r','t','m')
ORDER BY age(c.relfrozenxid) DESC
LIMIT 20;

--wraparound db
SELECT
    d.datname,
    age(d.datfrozenxid) AS xid_age,
    to_char(2147483647 - age(d.datfrozenxid), 'FM999,999,999,990') AS to_limit,
    pg_size_pretty(pg_database_size(d.oid)) AS total_size
FROM pg_database d
ORDER BY age(d.datfrozenxid) DESC;

--Missing grants
SELECT  
	CASE c.relkind WHEN 'r' THEN 'table' WHEN 'v' THEN 'view' WHEN 'S' THEN 'sequence' END as "Type", 
	n.nspname||'.'||c.relname as "Name",
	c.relacl as "Access privileges" 
FROM pg_catalog.pg_class c 
LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace 
WHERE 
c.relkind IN ('r', 'v', 'S') 
AND n.nspname !~ '^pg_' 
AND n.nspname not in ('information_schema', '_slony', 'tables_to_drop') 
AND (
	c.relacl IS NULL 
	OR c.relacl::text not like '%role_ro=r/%'
	OR CASE c.relkind 
	WHEN 'r' THEN c.relacl::text not like '%role_rw=arwd/%'
	WHEN 'v' THEN c.relacl::text not like '%role_rw=r/%'
	WHEN 'S' THEN c.relacl::text not like '%role_rw=rU/%'
	END
) 
ORDER BY 1, 2;


--Display query which are in lock, how long they have been running

SELECT a.datname,
    c.relname,
    l.transactionid,
    l.mode,
    l.GRANTED,
    a.usename,
    a.query,
    a.query_start,
    age(now(), a.query_start) AS "age",
    a.pid
FROM pg_stat_activity a
    JOIN pg_locks         l ON l.pid = a.pid
    JOIN pg_class         c ON c.oid = l.relation
ORDER BY a.query_start;


--Title:vacuum thresholds and more
SELECT
    pg_stat_user_tables.relname,
    pg_stat_user_tables.n_dead_tup,
    50 + 0.1 * pg_class.reltuples as vacuum_threshold,
    pg_class.reltuples,
    pg_stat_user_tables.n_live_tup,
    pg_stat_user_tables.n_tup_del,
    pg_stat_user_tables.n_tup_upd,
    pg_stat_user_tables.autovacuum_count,
    pg_stat_user_tables.last_vacuum,
    pg_stat_user_tables.last_autovacuum,
    now() as now,
    pg_stat_user_tables.n_dead_tup
>
(50 + 0.1 * pg_class.reltuples) as is_vacuum
FROM
   pg_stat_user_tables INNER JOIN pg_class ON pg_stat_user_tables.relname = pg_class.relname
ORDER BY
   pg_stat_user_tables.n_dead_tup >
(50 + 0.1 * pg_class.reltuples) DESC;

--Title: estimate wasted space in DB
Source: https://wiki.postgresql.org/wiki/Show_database_bloat
Query: SELECT
  current_database(), schemaname, tablename, /*reltuples::bigint, relpages::bigint, otta,*/
  ROUND((CASE WHEN otta=0 THEN 0.0 ELSE sml.relpages::FLOAT/otta END)::NUMERIC,1) AS tbloat,
  CASE WHEN relpages < otta THEN 0 ELSE bs*(sml.relpages-otta)::BIGINT END AS wastedbytes,
  iname, /*ituples::bigint, ipages::bigint, iotta,*/
  ROUND((CASE WHEN iotta=0 OR ipages=0 THEN 0.0 ELSE ipages::FLOAT/iotta END)::NUMERIC,1) AS ibloat,
  CASE WHEN ipages < iotta THEN 0 ELSE bs*(ipages-iotta) END AS wastedibytes
FROM (
  SELECT
    schemaname, tablename, cc.reltuples, cc.relpages, bs,
    CEIL((cc.reltuples*((datahdr+ma-
      (CASE WHEN datahdr%ma=0 THEN ma ELSE datahdr%ma END))+nullhdr2+4))/(bs-20::FLOAT)) AS otta,
    COALESCE(c2.relname,'?') AS iname, COALESCE(c2.reltuples,0) AS ituples, COALESCE(c2.relpages,0) AS ipages,
    COALESCE(CEIL((c2.reltuples*(datahdr-12))/(bs-20::FLOAT)),0) AS iotta -- very rough approximation, assumes all cols
  FROM (
    SELECT
      ma,bs,schemaname,tablename,
      (datawidth+(hdr+ma-(CASE WHEN hdr%ma=0 THEN ma ELSE hdr%ma END)))::NUMERIC AS datahdr,
      (maxfracsum*(nullhdr+ma-(CASE WHEN nullhdr%ma=0 THEN ma ELSE nullhdr%ma END))) AS nullhdr2
    FROM (
      SELECT
        schemaname, tablename, hdr, ma, bs,
        SUM((1-null_frac)*avg_width) AS datawidth,
        MAX(null_frac) AS maxfracsum,
        hdr+(
          SELECT 1+COUNT(*)/8
          FROM pg_stats s2
          WHERE null_frac<>0 AND s2.schemaname = s.schemaname AND s2.tablename = s.tablename
        ) AS nullhdr
      FROM pg_stats s, (
        SELECT
          (SELECT current_setting('block_size')::NUMERIC) AS bs,
          CASE WHEN SUBSTRING(v,12,3) IN ('8.0','8.1','8.2') THEN 27 ELSE 23 END AS hdr,
          CASE WHEN v ~ 'mingw32' THEN 8 ELSE 4 END AS ma
        FROM (SELECT version() AS v) AS foo
      ) AS constants
      GROUP BY 1,2,3,4,5
    ) AS foo
  ) AS rs
  JOIN pg_class cc ON cc.relname = rs.tablename
  JOIN pg_namespace nn ON cc.relnamespace = nn.oid AND nn.nspname = rs.schemaname AND nn.nspname <> 'information_schema'
  LEFT JOIN pg_index i ON indrelid = cc.oid
  LEFT JOIN pg_class c2 ON c2.oid = i.indexrelid
) AS sml
ORDER BY wastedbytes DESC;

--Constraint DDL 
-- https://dba.stackexchange.com/a/298038/272968
SELECT
    connamespace::regnamespace
AS schema,
  conrelid::regclass AS table,
  conname AS constraint,
  pg_get_constraintdef
(oid) AS definition,
  format
('ALTER TABLE %I.%I ADD CONSTRAINT %I %s;', connamespace::regnamespace,
   conrelid::regclass,
   conname,
   pg_get_constraintdef
(oid) ) 
FROM
  pg_constraint 
WHERE
  conname IN
('fk_rails_e7560abc33');

---- Get activity and lock state
SELECT (clock_timestamp() - a.query_start) > '00:01:00'::interval AS long_tx,
   a.pid,
   u.usename AS username,
   a.wait_event_type,
   clock_timestamp() - a.query_start AS "time",
   kl.pid AS b_pid,
   a.state,
   a.query
  FROM pg_stat_activity a
    JOIN pg_user u ON a.usesysid = u.usesysid
    LEFT JOIN pg_locks l ON l.pid = a.pid AND NOT l.granted
    LEFT JOIN pg_locks kl ON l.transactionid = kl.transactionid AND l.pid <> kl.pid
 WHERE 
    a.query <> '<IDLE>'::text 
    -- AND NOT a.query ~~ '%-- ME%'::text 
    AND a.pid <> pg_backend_pid() 
    AND a.state <> 'idle'::text
 ORDER BY a.query_start;

 -- Get blocking and blocked queries. 
-- 
WITH
    blocked_queries
    AS
    (
        SELECT
            pid,
            query,
            array_agg( distinct pg_blocking_pids(pid)) as "BlockingPids",
            count(pl.*) as "NumLocks",
            array_agg( pl.mode) as "Modes"
        FROM pg_stat_activity pa join pg_locks pl  using (pid)
        WHERE wait_event IS NOT NULL
            AND pg_blocking_pids(pid)<> '{}'
        group by pid,query
    ),
    blocking_query
    AS
    (
        SELECT pid, query, array_agg(distinct pid),
            count(pl.*) as "NumLocks",
            array_agg(pl.mode) as "Modes"
        FROM pg_stat_activity pa JOIN pg_locks pl  USING (pid)
        WHERE pid IN (select distinct unnest(pg_blocking_pids(pid))
        FROM pg_stat_activity)
        group by pid, query
    )
    SELECT *
    FROM blocked_queries
UNION
    SELECT *
    FROM blocking_query
;

/* 
Shows the percentage towards Wraparound and Emergency Autovacuum (it can be added to monitoring system for alerting)
for the entire cluster
*/

WITH
    max_age
    AS
    (
        SELECT
            2000000000 AS max_old_xid, -- two billions
            setting AS autovacuum_freeze_max_age
        FROM
            pg_catalog.pg_settings
        WHERE
    name = 'autovacuum_freeze_max_age'
    ),
    per_database_stats
    AS
    (
        SELECT
            datname,
            m.max_old_xid::int,
            m.autovacuum_freeze_max_age::int,
            age(d.datfrozenxid) AS oldest_current_xid
        FROM
            pg_catalog.pg_database d
            JOIN max_age m ON (true)
        WHERE
    d.datallowconn
    )
SELECT
    max(oldest_current_xid) AS oldest_current_xid,
    max(ROUND(100*(oldest_current_xid/max_old_xid::float))) AS percent_towards_wraparound,
    max(ROUND(100*(oldest_current_xid/autovacuum_freeze_max_age::float))) AS percent_towards_emergency_autovacuum
FROM
    per_database_stats;
